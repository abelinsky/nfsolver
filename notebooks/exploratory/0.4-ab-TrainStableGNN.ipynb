{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение GNN-модели на датасете графов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.data.hydrodataset import HydroDataset\n",
    "\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "from src.models.gnnstableprocessor import GNNStableProcessor\n",
    "from src.visualization.visualize import visualize_graph\n",
    "from src.models.train_model import HydraulicsLoss, MultiHydraulicsLoss\n",
    "\n",
    "from torch_geometric.nn import summary\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 80\n"
     ]
    }
   ],
   "source": [
    "dataset = HydroDataset(root=\"/tmp/hydro\")\n",
    "train_ds = dataset #[:2]\n",
    "print(\"Dataset length:\", len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = to_networkx(train_ds[1], to_undirected=False)\n",
    "visualize_graph(G, color=dataset[0].x[..., 1] == 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNStableProcessor(\n",
      "  (convs): ModuleList(\n",
      "    (0-19): 20 x GNNSConv(aggr=mean, latent_dim=64, alpha=0.1, hidden_layers=[64])\n",
      "  )\n",
      "  (final): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (balance_conv): BalanceConv()\n",
      "  (decoders): ModuleList(\n",
      "    (0-19): 20 x Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GNNStableProcessor(out_channels=1, \n",
    "                     num_edge_features=dataset.num_edge_features, \n",
    "                     latent_dim=64, \n",
    "                     num_convs=20, \n",
    "                     convs_hidden_layers=[64],\n",
    "                     alpha_update_x=0.1,\n",
    "                     aggr=\"mean\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MultiHydraulicsLoss(gamma=0.9)\n",
    "info_criterion = HydraulicsLoss(name='Info loss')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train(pretrain_data=None):\n",
    "  model.train()\n",
    "\n",
    "  total_loss = 0\n",
    "  for data in loader if pretrain_data is None else [pretrain_data]:\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    P, _, imbalance_list = model(data)\n",
    "    # imbalance_list = imbalance_list.squeeze()\n",
    "    # print(f\"{imbalance_list=}\")\n",
    "    loss = criterion(data, P, imbalance_list)\n",
    "\n",
    "    # Вычисление информационного loss на последнем слое GNN\n",
    "    info_loss = info_criterion(data, P, imbalance_list[-1, ...].unsqueeze(0))\n",
    "\n",
    "    # total_loss += loss.item() * data.num_graphs if pretrain_data is None else loss.item()\n",
    "    total_loss += info_loss.item() * data.num_graphs if pretrain_data is None else info_loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  \n",
    "    optimizer.step()\n",
    "\n",
    "  total_loss = total_loss / len(loader.dataset) if pretrain_data is None else total_loss\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pretrain the model\n",
    "# for epoch in range(250):\n",
    "#   loss = train(train_ds[0])\n",
    "#   if (epoch % 10 == 0):\n",
    "#     print(f'Pretraining epoch: {epoch:03d}, Loss: {loss:.4f}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 8260.6526\n",
      "Epoch: 010, Loss: 1964.6963\n",
      "Epoch: 020, Loss: 806.7155\n",
      "Epoch: 030, Loss: 842.7050\n",
      "Epoch: 040, Loss: 982.1847\n",
      "Epoch: 050, Loss: 1010.0438\n",
      "Epoch: 060, Loss: 1049.3295\n",
      "Epoch: 070, Loss: 877.5761\n",
      "Epoch: 080, Loss: 813.0755\n",
      "Epoch: 090, Loss: 867.9874\n",
      "Epoch: 100, Loss: 725.5953\n",
      "Epoch: 110, Loss: 720.7188\n",
      "Epoch: 120, Loss: 785.4489\n",
      "Epoch: 130, Loss: 888.2355\n",
      "Epoch: 140, Loss: 691.4835\n",
      "Epoch: 150, Loss: 720.9658\n",
      "Epoch: 160, Loss: 701.9263\n",
      "Epoch: 170, Loss: 612.1560\n",
      "Epoch: 180, Loss: 572.4200\n",
      "Epoch: 190, Loss: 665.1470\n",
      "Epoch: 200, Loss: 564.3619\n",
      "Epoch: 210, Loss: 962.8928\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39mif\u001b[39;00m (epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n",
      "\u001b[1;32m/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m P, _, imbalance_list \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# imbalance_list = imbalance_list.squeeze()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# print(f\"{imbalance_list=}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ab/apps/ml/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(data, P, imbalance_list)\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/apps/ml/nfsolver/src/models/gnnstableprocessor.py:46\u001b[0m, in \u001b[0;36mGNNStableProcessor.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     43\u001b[0m     imbalance_list\u001b[39m.\u001b[39mappend(imbalance)\n\u001b[1;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m conv, decoder \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoders):\n\u001b[0;32m---> 46\u001b[0m     X \u001b[39m=\u001b[39m conv(X, edge_index, node_attr, edge_attr)\n\u001b[1;32m     47\u001b[0m     X \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(X)\n\u001b[1;32m     48\u001b[0m     Pl \u001b[39m=\u001b[39m decoder(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/apps/ml/nfsolver/src/models/gnnsvonv.py:90\u001b[0m, in \u001b[0;36mGNNSConv.forward\u001b[0;34m(self, X, edge_index, node_attr, edge_attr)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39m# Формирование сообщения i -> j\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtarget_to_source\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 90\u001b[0m phi_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mX, edge_attr\u001b[39m=\u001b[39;49medge_attr)\n\u001b[1;32m     92\u001b[0m \u001b[39m# Объединение сообщений\u001b[39;00m\n\u001b[1;32m     93\u001b[0m inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([X, node_attr, phi_in, phi_out], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:467\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 467\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[1;32m    468\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    469\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m~/apps/ml/nfsolver/src/models/gnnsvonv.py:107\u001b[0m, in \u001b[0;36mGNNSConv.message\u001b[0;34m(self, x_i, x_j, edge_attr)\u001b[0m\n\u001b[1;32m    105\u001b[0m mlp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_in \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msource_to_target\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_out\n\u001b[1;32m    106\u001b[0m tmp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x_j, x_i, edge_attr], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m out_message \u001b[39m=\u001b[39m mlp(tmp)\n\u001b[1;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m out_message\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "  loss = train()\n",
    "  losses.append(loss)\n",
    "\n",
    "  if (epoch % 10 == 0):\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Кривая обучения')\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('Функция потерь')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([\n",
    "  [0, 1, 2],\n",
    "  [1, 2, 3]\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Структура данных атрибутов вершин графа:\n",
    "# Расход газа потребителя в узле, млн м3/сут; Давление газа, МПа\n",
    "x = torch.tensor([[0, 7.4], [0.0, 0], [0, 0], [0, 5.4]], dtype=torch.float32)\n",
    "\n",
    "# Структура данных атрибутов дуг графа:\n",
    "# Протяженность, км; Внутренний диаметр трубы, мм\n",
    "edge_attr = torch.tensor([\n",
    "  [38, 1400],\n",
    "  [40, 1400],\n",
    "  [43, 1400]\n",
    "])\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=tensor([[1.7250],\n",
      "        [5.8743],\n",
      "        [5.5691],\n",
      "        [3.9446]], grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 152.3783],\n",
      "         [ -21.8183],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 157.1003],\n",
      "         [  40.1104],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0168],\n",
      "         [  56.1030],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.8715],\n",
      "         [  58.9604],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0012],\n",
      "         [  60.6186],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 152.1137],\n",
      "         [  57.8501],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.6870],\n",
      "         [  58.1968],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.7664],\n",
      "         [  57.9022],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9002],\n",
      "         [  58.5722],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.0973],\n",
      "         [  59.9053],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.3543],\n",
      "         [  61.0600],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9813],\n",
      "         [  58.4135],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.1660],\n",
      "         [  58.0462],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.4966],\n",
      "         [  58.0694],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.7034],\n",
      "         [  58.7567],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.5866],\n",
      "         [  58.3450],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.2336],\n",
      "         [  59.8826],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.3795],\n",
      "         [  60.5379],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.5021],\n",
      "         [  60.1539],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 147.8977],\n",
      "         [  59.8614],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-152.3783],\n",
      "         [ 174.1966],\n",
      "         [ -87.8285],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[-157.1003],\n",
      "         [ 116.9899],\n",
      "         [   6.5455],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[-153.0168],\n",
      "         [  96.9138],\n",
      "         [  27.5657],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[-149.8715],\n",
      "         [  90.9111],\n",
      "         [  22.2120],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-153.0012],\n",
      "         [  92.3826],\n",
      "         [  42.4998],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[-152.1137],\n",
      "         [  94.2635],\n",
      "         [  28.3086],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[-151.6870],\n",
      "         [  93.4901],\n",
      "         [  27.3776],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[-151.7664],\n",
      "         [  93.8642],\n",
      "         [  26.9128],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[-150.9002],\n",
      "         [  92.3280],\n",
      "         [  25.1143],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[-151.0973],\n",
      "         [  91.1920],\n",
      "         [  29.5751],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[-150.3543],\n",
      "         [  89.2944],\n",
      "         [  29.6290],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[-150.9813],\n",
      "         [  92.5678],\n",
      "         [  25.0206],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[-150.1660],\n",
      "         [  92.1199],\n",
      "         [  21.0078],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[-150.4966],\n",
      "         [  92.4272],\n",
      "         [  22.2713],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[-150.7034],\n",
      "         [  91.9466],\n",
      "         [  24.8191],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[-149.5866],\n",
      "         [  91.2416],\n",
      "         [  19.7060],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[-149.2336],\n",
      "         [  89.3510],\n",
      "         [  22.2383],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[-148.3795],\n",
      "         [  87.8416],\n",
      "         [  20.9360],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[-148.5021],\n",
      "         [  88.3482],\n",
      "         [  20.4141],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[-147.8977],\n",
      "         [  88.0363],\n",
      "         [  17.7871],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "P=tensor([[1.7250],\n",
      "        [5.8743],\n",
      "        [5.5691],\n",
      "        [3.9446]], grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 152.3783],\n",
      "         [ -21.8183],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 157.1003],\n",
      "         [  40.1104],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0168],\n",
      "         [  56.1030],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.8715],\n",
      "         [  58.9604],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0012],\n",
      "         [  60.6186],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 152.1137],\n",
      "         [  57.8501],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.6870],\n",
      "         [  58.1968],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.7664],\n",
      "         [  57.9022],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9002],\n",
      "         [  58.5722],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.0973],\n",
      "         [  59.9053],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.3543],\n",
      "         [  61.0600],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9813],\n",
      "         [  58.4135],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.1660],\n",
      "         [  58.0462],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.4966],\n",
      "         [  58.0694],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.7034],\n",
      "         [  58.7567],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.5866],\n",
      "         [  58.3450],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.2336],\n",
      "         [  59.8826],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.3795],\n",
      "         [  60.5379],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.5021],\n",
      "         [  60.1539],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 147.8977],\n",
      "         [  59.8614],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-152.3783],\n",
      "         [ 174.1966],\n",
      "         [ -87.8285],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[-157.1003],\n",
      "         [ 116.9899],\n",
      "         [   6.5455],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[-153.0168],\n",
      "         [  96.9138],\n",
      "         [  27.5657],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[-149.8715],\n",
      "         [  90.9111],\n",
      "         [  22.2120],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-153.0012],\n",
      "         [  92.3826],\n",
      "         [  42.4998],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[-152.1137],\n",
      "         [  94.2635],\n",
      "         [  28.3086],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[-151.6870],\n",
      "         [  93.4901],\n",
      "         [  27.3776],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[-151.7664],\n",
      "         [  93.8642],\n",
      "         [  26.9128],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[-150.9002],\n",
      "         [  92.3280],\n",
      "         [  25.1143],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[-151.0973],\n",
      "         [  91.1920],\n",
      "         [  29.5751],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[-150.3543],\n",
      "         [  89.2944],\n",
      "         [  29.6290],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[-150.9813],\n",
      "         [  92.5678],\n",
      "         [  25.0206],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[-150.1660],\n",
      "         [  92.1199],\n",
      "         [  21.0078],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[-150.4966],\n",
      "         [  92.4272],\n",
      "         [  22.2713],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[-150.7034],\n",
      "         [  91.9466],\n",
      "         [  24.8191],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[-149.5866],\n",
      "         [  91.2416],\n",
      "         [  19.7060],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[-149.2336],\n",
      "         [  89.3510],\n",
      "         [  22.2383],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[-148.3795],\n",
      "         [  87.8416],\n",
      "         [  20.9360],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[-148.5021],\n",
      "         [  88.3482],\n",
      "         [  20.4141],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[-147.8977],\n",
      "         [  88.0363],\n",
      "         [  17.7871],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "P=tensor([[1.7250],\n",
      "        [5.8743],\n",
      "        [5.5691],\n",
      "        [3.9446]], grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 152.3783],\n",
      "         [ -21.8183],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 157.1003],\n",
      "         [  40.1104],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0168],\n",
      "         [  56.1030],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.8715],\n",
      "         [  58.9604],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0012],\n",
      "         [  60.6186],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 152.1137],\n",
      "         [  57.8501],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.6870],\n",
      "         [  58.1968],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.7664],\n",
      "         [  57.9022],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9002],\n",
      "         [  58.5722],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.0973],\n",
      "         [  59.9053],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.3543],\n",
      "         [  61.0600],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9813],\n",
      "         [  58.4135],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.1660],\n",
      "         [  58.0462],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.4966],\n",
      "         [  58.0694],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.7034],\n",
      "         [  58.7567],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.5866],\n",
      "         [  58.3450],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.2336],\n",
      "         [  59.8826],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.3795],\n",
      "         [  60.5379],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.5021],\n",
      "         [  60.1539],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 147.8977],\n",
      "         [  59.8614],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-152.3783],\n",
      "         [ 174.1966],\n",
      "         [ -87.8285],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[-157.1003],\n",
      "         [ 116.9899],\n",
      "         [   6.5455],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[-153.0168],\n",
      "         [  96.9138],\n",
      "         [  27.5657],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[-149.8715],\n",
      "         [  90.9111],\n",
      "         [  22.2120],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-153.0012],\n",
      "         [  92.3826],\n",
      "         [  42.4998],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[-152.1137],\n",
      "         [  94.2635],\n",
      "         [  28.3086],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[-151.6870],\n",
      "         [  93.4901],\n",
      "         [  27.3776],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[-151.7664],\n",
      "         [  93.8642],\n",
      "         [  26.9128],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[-150.9002],\n",
      "         [  92.3280],\n",
      "         [  25.1143],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[-151.0973],\n",
      "         [  91.1920],\n",
      "         [  29.5751],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[-150.3543],\n",
      "         [  89.2944],\n",
      "         [  29.6290],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[-150.9813],\n",
      "         [  92.5678],\n",
      "         [  25.0206],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[-150.1660],\n",
      "         [  92.1199],\n",
      "         [  21.0078],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[-150.4966],\n",
      "         [  92.4272],\n",
      "         [  22.2713],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[-150.7034],\n",
      "         [  91.9466],\n",
      "         [  24.8191],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[-149.5866],\n",
      "         [  91.2416],\n",
      "         [  19.7060],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[-149.2336],\n",
      "         [  89.3510],\n",
      "         [  22.2383],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[-148.3795],\n",
      "         [  87.8416],\n",
      "         [  20.9360],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[-148.5021],\n",
      "         [  88.3482],\n",
      "         [  20.4141],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[-147.8977],\n",
      "         [  88.0363],\n",
      "         [  17.7871],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "P=tensor([[1.7250],\n",
      "        [5.8743],\n",
      "        [5.5691],\n",
      "        [3.9446]], grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 152.3783],\n",
      "         [ -21.8183],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 157.1003],\n",
      "         [  40.1104],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0168],\n",
      "         [  56.1030],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.8715],\n",
      "         [  58.9604],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0012],\n",
      "         [  60.6186],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 152.1137],\n",
      "         [  57.8501],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.6870],\n",
      "         [  58.1968],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.7664],\n",
      "         [  57.9022],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9002],\n",
      "         [  58.5722],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.0973],\n",
      "         [  59.9053],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.3543],\n",
      "         [  61.0600],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9813],\n",
      "         [  58.4135],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.1660],\n",
      "         [  58.0462],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.4966],\n",
      "         [  58.0694],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.7034],\n",
      "         [  58.7567],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.5866],\n",
      "         [  58.3450],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.2336],\n",
      "         [  59.8826],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.3795],\n",
      "         [  60.5379],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.5021],\n",
      "         [  60.1539],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 147.8977],\n",
      "         [  59.8614],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-152.3783],\n",
      "         [ 174.1966],\n",
      "         [ -87.8285],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[-157.1003],\n",
      "         [ 116.9899],\n",
      "         [   6.5455],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[-153.0168],\n",
      "         [  96.9138],\n",
      "         [  27.5657],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[-149.8715],\n",
      "         [  90.9111],\n",
      "         [  22.2120],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-153.0012],\n",
      "         [  92.3826],\n",
      "         [  42.4998],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[-152.1137],\n",
      "         [  94.2635],\n",
      "         [  28.3086],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[-151.6870],\n",
      "         [  93.4901],\n",
      "         [  27.3776],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[-151.7664],\n",
      "         [  93.8642],\n",
      "         [  26.9128],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[-150.9002],\n",
      "         [  92.3280],\n",
      "         [  25.1143],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[-151.0973],\n",
      "         [  91.1920],\n",
      "         [  29.5751],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[-150.3543],\n",
      "         [  89.2944],\n",
      "         [  29.6290],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[-150.9813],\n",
      "         [  92.5678],\n",
      "         [  25.0206],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[-150.1660],\n",
      "         [  92.1199],\n",
      "         [  21.0078],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[-150.4966],\n",
      "         [  92.4272],\n",
      "         [  22.2713],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[-150.7034],\n",
      "         [  91.9466],\n",
      "         [  24.8191],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[-149.5866],\n",
      "         [  91.2416],\n",
      "         [  19.7060],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[-149.2336],\n",
      "         [  89.3510],\n",
      "         [  22.2383],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[-148.3795],\n",
      "         [  87.8416],\n",
      "         [  20.9360],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[-148.5021],\n",
      "         [  88.3482],\n",
      "         [  20.4141],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[-147.8977],\n",
      "         [  88.0363],\n",
      "         [  17.7871],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "P=tensor([[1.7250],\n",
      "        [5.8743],\n",
      "        [5.5691],\n",
      "        [3.9446]], grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 152.3783],\n",
      "         [ -21.8183],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 157.1003],\n",
      "         [  40.1104],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0168],\n",
      "         [  56.1030],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.8715],\n",
      "         [  58.9604],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0012],\n",
      "         [  60.6186],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 152.1137],\n",
      "         [  57.8501],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.6870],\n",
      "         [  58.1968],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.7664],\n",
      "         [  57.9022],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9002],\n",
      "         [  58.5722],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.0973],\n",
      "         [  59.9053],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.3543],\n",
      "         [  61.0600],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9813],\n",
      "         [  58.4135],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.1660],\n",
      "         [  58.0462],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.4966],\n",
      "         [  58.0694],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.7034],\n",
      "         [  58.7567],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.5866],\n",
      "         [  58.3450],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.2336],\n",
      "         [  59.8826],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.3795],\n",
      "         [  60.5379],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.5021],\n",
      "         [  60.1539],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 147.8977],\n",
      "         [  59.8614],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-152.3783],\n",
      "         [ 174.1966],\n",
      "         [ -87.8285],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[-157.1003],\n",
      "         [ 116.9899],\n",
      "         [   6.5455],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[-153.0168],\n",
      "         [  96.9138],\n",
      "         [  27.5657],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[-149.8715],\n",
      "         [  90.9111],\n",
      "         [  22.2120],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-153.0012],\n",
      "         [  92.3826],\n",
      "         [  42.4998],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[-152.1137],\n",
      "         [  94.2635],\n",
      "         [  28.3086],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[-151.6870],\n",
      "         [  93.4901],\n",
      "         [  27.3776],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[-151.7664],\n",
      "         [  93.8642],\n",
      "         [  26.9128],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[-150.9002],\n",
      "         [  92.3280],\n",
      "         [  25.1143],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[-151.0973],\n",
      "         [  91.1920],\n",
      "         [  29.5751],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[-150.3543],\n",
      "         [  89.2944],\n",
      "         [  29.6290],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[-150.9813],\n",
      "         [  92.5678],\n",
      "         [  25.0206],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[-150.1660],\n",
      "         [  92.1199],\n",
      "         [  21.0078],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[-150.4966],\n",
      "         [  92.4272],\n",
      "         [  22.2713],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[-150.7034],\n",
      "         [  91.9466],\n",
      "         [  24.8191],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[-149.5866],\n",
      "         [  91.2416],\n",
      "         [  19.7060],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[-149.2336],\n",
      "         [  89.3510],\n",
      "         [  22.2383],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[-148.3795],\n",
      "         [  87.8416],\n",
      "         [  20.9360],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[-148.5021],\n",
      "         [  88.3482],\n",
      "         [  20.4141],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[-147.8977],\n",
      "         [  88.0363],\n",
      "         [  17.7871],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "P=tensor([[1.7250],\n",
      "        [5.8743],\n",
      "        [5.5691],\n",
      "        [3.9446]], grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 152.3783],\n",
      "         [ -21.8183],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 157.1003],\n",
      "         [  40.1104],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0168],\n",
      "         [  56.1030],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.8715],\n",
      "         [  58.9604],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0012],\n",
      "         [  60.6186],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 152.1137],\n",
      "         [  57.8501],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.6870],\n",
      "         [  58.1968],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.7664],\n",
      "         [  57.9022],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9002],\n",
      "         [  58.5722],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.0973],\n",
      "         [  59.9053],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.3543],\n",
      "         [  61.0600],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9813],\n",
      "         [  58.4135],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.1660],\n",
      "         [  58.0462],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.4966],\n",
      "         [  58.0694],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.7034],\n",
      "         [  58.7567],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.5866],\n",
      "         [  58.3450],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.2336],\n",
      "         [  59.8826],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.3795],\n",
      "         [  60.5379],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.5021],\n",
      "         [  60.1539],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 147.8977],\n",
      "         [  59.8614],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-152.3783],\n",
      "         [ 174.1966],\n",
      "         [ -87.8285],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[-157.1003],\n",
      "         [ 116.9899],\n",
      "         [   6.5455],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[-153.0168],\n",
      "         [  96.9138],\n",
      "         [  27.5657],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[-149.8715],\n",
      "         [  90.9111],\n",
      "         [  22.2120],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-153.0012],\n",
      "         [  92.3826],\n",
      "         [  42.4998],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[-152.1137],\n",
      "         [  94.2635],\n",
      "         [  28.3086],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[-151.6870],\n",
      "         [  93.4901],\n",
      "         [  27.3776],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[-151.7664],\n",
      "         [  93.8642],\n",
      "         [  26.9128],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[-150.9002],\n",
      "         [  92.3280],\n",
      "         [  25.1143],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[-151.0973],\n",
      "         [  91.1920],\n",
      "         [  29.5751],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[-150.3543],\n",
      "         [  89.2944],\n",
      "         [  29.6290],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[-150.9813],\n",
      "         [  92.5678],\n",
      "         [  25.0206],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[-150.1660],\n",
      "         [  92.1199],\n",
      "         [  21.0078],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[-150.4966],\n",
      "         [  92.4272],\n",
      "         [  22.2713],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[-150.7034],\n",
      "         [  91.9466],\n",
      "         [  24.8191],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[-149.5866],\n",
      "         [  91.2416],\n",
      "         [  19.7060],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[-149.2336],\n",
      "         [  89.3510],\n",
      "         [  22.2383],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[-148.3795],\n",
      "         [  87.8416],\n",
      "         [  20.9360],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[-148.5021],\n",
      "         [  88.3482],\n",
      "         [  20.4141],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[-147.8977],\n",
      "         [  88.0363],\n",
      "         [  17.7871],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "P=tensor([[1.7250],\n",
      "        [5.8743],\n",
      "        [5.5691],\n",
      "        [3.9446]], grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 152.3783],\n",
      "         [ -21.8183],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 157.1003],\n",
      "         [  40.1104],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0168],\n",
      "         [  56.1030],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.8715],\n",
      "         [  58.9604],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0012],\n",
      "         [  60.6186],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 152.1137],\n",
      "         [  57.8501],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.6870],\n",
      "         [  58.1968],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.7664],\n",
      "         [  57.9022],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9002],\n",
      "         [  58.5722],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.0973],\n",
      "         [  59.9053],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.3543],\n",
      "         [  61.0600],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9813],\n",
      "         [  58.4135],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.1660],\n",
      "         [  58.0462],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.4966],\n",
      "         [  58.0694],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.7034],\n",
      "         [  58.7567],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.5866],\n",
      "         [  58.3450],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.2336],\n",
      "         [  59.8826],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.3795],\n",
      "         [  60.5379],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.5021],\n",
      "         [  60.1539],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 147.8977],\n",
      "         [  59.8614],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-152.3783],\n",
      "         [ 174.1966],\n",
      "         [ -87.8285],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[-157.1003],\n",
      "         [ 116.9899],\n",
      "         [   6.5455],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[-153.0168],\n",
      "         [  96.9138],\n",
      "         [  27.5657],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[-149.8715],\n",
      "         [  90.9111],\n",
      "         [  22.2120],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-153.0012],\n",
      "         [  92.3826],\n",
      "         [  42.4998],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[-152.1137],\n",
      "         [  94.2635],\n",
      "         [  28.3086],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[-151.6870],\n",
      "         [  93.4901],\n",
      "         [  27.3776],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[-151.7664],\n",
      "         [  93.8642],\n",
      "         [  26.9128],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[-150.9002],\n",
      "         [  92.3280],\n",
      "         [  25.1143],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[-151.0973],\n",
      "         [  91.1920],\n",
      "         [  29.5751],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[-150.3543],\n",
      "         [  89.2944],\n",
      "         [  29.6290],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[-150.9813],\n",
      "         [  92.5678],\n",
      "         [  25.0206],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[-150.1660],\n",
      "         [  92.1199],\n",
      "         [  21.0078],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[-150.4966],\n",
      "         [  92.4272],\n",
      "         [  22.2713],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[-150.7034],\n",
      "         [  91.9466],\n",
      "         [  24.8191],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[-149.5866],\n",
      "         [  91.2416],\n",
      "         [  19.7060],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[-149.2336],\n",
      "         [  89.3510],\n",
      "         [  22.2383],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[-148.3795],\n",
      "         [  87.8416],\n",
      "         [  20.9360],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[-148.5021],\n",
      "         [  88.3482],\n",
      "         [  20.4141],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[-147.8977],\n",
      "         [  88.0363],\n",
      "         [  17.7871],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "P=tensor([[1.7250],\n",
      "        [5.8743],\n",
      "        [5.5691],\n",
      "        [3.9446]], grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 152.3783],\n",
      "         [ -21.8183],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 157.1003],\n",
      "         [  40.1104],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0168],\n",
      "         [  56.1030],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.8715],\n",
      "         [  58.9604],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 153.0012],\n",
      "         [  60.6186],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 152.1137],\n",
      "         [  57.8501],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.6870],\n",
      "         [  58.1968],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.7664],\n",
      "         [  57.9022],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9002],\n",
      "         [  58.5722],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 151.0973],\n",
      "         [  59.9053],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.3543],\n",
      "         [  61.0600],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.9813],\n",
      "         [  58.4135],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.1660],\n",
      "         [  58.0462],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.4966],\n",
      "         [  58.0694],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 150.7034],\n",
      "         [  58.7567],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.5866],\n",
      "         [  58.3450],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 149.2336],\n",
      "         [  59.8826],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.3795],\n",
      "         [  60.5379],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 148.5021],\n",
      "         [  60.1539],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 147.8977],\n",
      "         [  59.8614],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-152.3783],\n",
      "         [ 174.1966],\n",
      "         [ -87.8285],\n",
      "         [  66.0103]],\n",
      "\n",
      "        [[-157.1003],\n",
      "         [ 116.9899],\n",
      "         [   6.5455],\n",
      "         [  33.5649]],\n",
      "\n",
      "        [[-153.0168],\n",
      "         [  96.9138],\n",
      "         [  27.5657],\n",
      "         [  28.5373]],\n",
      "\n",
      "        [[-149.8715],\n",
      "         [  90.9111],\n",
      "         [  22.2120],\n",
      "         [  36.7483]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-153.0012],\n",
      "         [  92.3826],\n",
      "         [  42.4998],\n",
      "         [  18.1188]],\n",
      "\n",
      "        [[-152.1137],\n",
      "         [  94.2635],\n",
      "         [  28.3086],\n",
      "         [  29.5415]],\n",
      "\n",
      "        [[-151.6870],\n",
      "         [  93.4901],\n",
      "         [  27.3776],\n",
      "         [  30.8193]],\n",
      "\n",
      "        [[-151.7664],\n",
      "         [  93.8642],\n",
      "         [  26.9128],\n",
      "         [  30.9894]],\n",
      "\n",
      "        [[-150.9002],\n",
      "         [  92.3280],\n",
      "         [  25.1143],\n",
      "         [  33.4579]],\n",
      "\n",
      "        [[-151.0973],\n",
      "         [  91.1920],\n",
      "         [  29.5751],\n",
      "         [  30.3302]],\n",
      "\n",
      "        [[-150.3543],\n",
      "         [  89.2944],\n",
      "         [  29.6290],\n",
      "         [  31.4310]],\n",
      "\n",
      "        [[-150.9813],\n",
      "         [  92.5678],\n",
      "         [  25.0206],\n",
      "         [  33.3928]],\n",
      "\n",
      "        [[-150.1660],\n",
      "         [  92.1199],\n",
      "         [  21.0078],\n",
      "         [  37.0383]],\n",
      "\n",
      "        [[-150.4966],\n",
      "         [  92.4272],\n",
      "         [  22.2713],\n",
      "         [  35.7981]],\n",
      "\n",
      "        [[-150.7034],\n",
      "         [  91.9466],\n",
      "         [  24.8191],\n",
      "         [  33.9376]],\n",
      "\n",
      "        [[-149.5866],\n",
      "         [  91.2416],\n",
      "         [  19.7060],\n",
      "         [  38.6390]],\n",
      "\n",
      "        [[-149.2336],\n",
      "         [  89.3510],\n",
      "         [  22.2383],\n",
      "         [  37.6443]],\n",
      "\n",
      "        [[-148.3795],\n",
      "         [  87.8416],\n",
      "         [  20.9360],\n",
      "         [  39.6019]],\n",
      "\n",
      "        [[-148.5021],\n",
      "         [  88.3482],\n",
      "         [  20.4141],\n",
      "         [  39.7399]],\n",
      "\n",
      "        [[-147.8977],\n",
      "         [  88.0363],\n",
      "         [  17.7871],\n",
      "         [  42.0743]]], grad_fn=<StackBackward0>)\n",
      "391 ms ± 36.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# %%timeit \n",
    "# Attention: При выводе значений давления краевые значения не выводятся, но учитываются в расчете\n",
    "P, flows, imbalance = model(data)\n",
    "print(f'{P=}')\n",
    "print(f'{flows=}')\n",
    "print(f'{imbalance=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/compile.py:28: UserWarning: Could not convert the 'model' into a jittable version. As such, 'torch.compile' may currently fail to correctly optimize your model. 'MessagePassing.jittable()' reported the following error: TorchScript support requires the definition of the types passed to `propagate()`. Please specify them via\n",
      "\n",
      "propagate_type = {\"arg1\": type1, \"arg2\": type2, ... }\n",
      "\n",
      "or via\n",
      "\n",
      "# propagate_type: (arg1: type1, arg2: type2, ...)\n",
      "\n",
      "inside the `MessagePassing` module.\n",
      "  warnings.warn(JIT_WARNING.format(error=e))\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "compiled = torch_geometric.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 ms ± 8.67 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "P, flows, imbalance = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfsolver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
