{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение GNN-модели на датасете графов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.data.hydrodataset import HydroDataset\n",
    "\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "from src.models.gnnstableprocessor import GNNStableProcessor\n",
    "from src.visualization.visualize import visualize_graph\n",
    "from src.models.train_model import HydraulicsLoss, MultiHydraulicsLoss\n",
    "\n",
    "from torch_geometric.nn import summary\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 32\n"
     ]
    }
   ],
   "source": [
    "dataset = HydroDataset(root=\"/tmp/hydro\")\n",
    "train_ds = dataset[48:]\n",
    "print(\"Dataset length:\", len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = to_networkx(train_ds[1], to_undirected=False)\n",
    "visualize_graph(G, color=dataset[0].x[..., 1] == 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNStableProcessor(\n",
      "  (convs): ModuleList(\n",
      "    (0-19): 20 x GNNSConv(aggr=mean, latent_dim=32, alpha=0.1, hidden_layers=[64])\n",
      "  )\n",
      "  (final): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (balance_conv): BalanceConv()\n",
      "  (decoders): ModuleList(\n",
      "    (0-19): 20 x Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = GNNStableProcessor(out_channels=1, \n",
    "                     num_edge_features=dataset.num_edge_features, \n",
    "                     latent_dim=32, \n",
    "                     num_convs=20, \n",
    "                     convs_hidden_layers=[64],\n",
    "                     alpha_update_x=0.1,\n",
    "                     aggr=\"mean\",\n",
    "                     device=device).to(device)\n",
    "\n",
    "print(model)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MultiHydraulicsLoss(gamma=0.75, device=device).to(device)\n",
    "info_criterion = HydraulicsLoss(name='Info loss').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pretrain_data=None):\n",
    "  model.train()\n",
    "\n",
    "  total_loss = 0\n",
    "  for data in loader if pretrain_data is None else [pretrain_data]:\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    P, _, imbalance_list = model(data)\n",
    "    loss = criterion(data, P, imbalance_list)\n",
    "    # Вычисление информационного loss на последнем слое GNN\n",
    "    info_loss = info_criterion(data, P, imbalance_list[-1, ...].unsqueeze(0))\n",
    "    # Отслеживание loss на последнем слое н/с \n",
    "    total_loss += info_loss.item() * data.num_graphs if pretrain_data is None else info_loss.item()\n",
    "    loss.backward()\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  \n",
    "    optimizer.step()\n",
    "\n",
    "  total_loss = total_loss / len(loader.dataset) if pretrain_data is None else total_loss\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain the model\n",
    "for epoch in range(250):\n",
    "  loss = train(train_ds[0])\n",
    "  if (epoch % 10 == 0):\n",
    "    print(f'Pretraining epoch: {epoch:03d}, Loss: {loss:.4f}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 12686.1260\n",
      "Epoch: 010, Loss: 3802.1108\n",
      "Epoch: 020, Loss: 2809.8721\n",
      "Epoch: 030, Loss: 937.7373\n",
      "Epoch: 040, Loss: 865.4983\n",
      "Epoch: 050, Loss: 809.8873\n",
      "Epoch: 060, Loss: 825.8790\n",
      "Epoch: 070, Loss: 819.8749\n",
      "Epoch: 080, Loss: 764.0891\n",
      "Epoch: 090, Loss: 744.2131\n",
      "Epoch: 100, Loss: 748.0605\n",
      "Epoch: 110, Loss: 814.6769\n",
      "Epoch: 120, Loss: 739.2277\n",
      "Epoch: 130, Loss: 726.8917\n",
      "Epoch: 140, Loss: 730.8054\n",
      "Epoch: 150, Loss: 745.3690\n",
      "Epoch: 160, Loss: 715.7343\n",
      "Epoch: 170, Loss: 772.9899\n",
      "Epoch: 180, Loss: 722.2490\n",
      "Epoch: 190, Loss: 788.2756\n",
      "Epoch: 200, Loss: 725.0705\n",
      "Epoch: 210, Loss: 830.5436\n",
      "Epoch: 220, Loss: 715.7833\n",
      "Epoch: 230, Loss: 907.2622\n",
      "Epoch: 240, Loss: 898.5283\n",
      "Epoch: 250, Loss: 708.1857\n",
      "Epoch: 260, Loss: 690.0870\n",
      "Epoch: 270, Loss: 681.8745\n",
      "Epoch: 280, Loss: 674.8505\n",
      "Epoch: 290, Loss: 672.1855\n",
      "Epoch: 300, Loss: 669.8146\n",
      "Epoch: 310, Loss: 670.7549\n",
      "Epoch: 320, Loss: 667.2339\n",
      "Epoch: 330, Loss: 664.1240\n",
      "Epoch: 340, Loss: 713.2304\n",
      "Epoch: 350, Loss: 662.1710\n",
      "Epoch: 360, Loss: 655.4494\n",
      "Epoch: 370, Loss: 686.2863\n",
      "Epoch: 380, Loss: 621.0217\n",
      "Epoch: 390, Loss: 846.9619\n",
      "Epoch: 400, Loss: 686.3527\n",
      "Epoch: 410, Loss: 685.6226\n",
      "Epoch: 420, Loss: 708.6374\n",
      "Epoch: 430, Loss: 674.4062\n",
      "Epoch: 440, Loss: 743.9111\n",
      "Epoch: 450, Loss: 663.2294\n",
      "Epoch: 460, Loss: 796.9553\n",
      "Epoch: 470, Loss: 1036.0492\n",
      "Epoch: 480, Loss: 659.0417\n",
      "Epoch: 490, Loss: 667.7183\n",
      "Epoch: 500, Loss: 673.7914\n",
      "Epoch: 510, Loss: 621.3983\n",
      "Epoch: 520, Loss: 605.8368\n",
      "Epoch: 530, Loss: 617.6422\n",
      "Epoch: 540, Loss: 513.6263\n",
      "Epoch: 550, Loss: 536.3164\n",
      "Epoch: 560, Loss: 530.8379\n",
      "Epoch: 570, Loss: 533.5211\n",
      "Epoch: 580, Loss: 526.1049\n",
      "Epoch: 590, Loss: 544.3486\n",
      "Epoch: 600, Loss: 539.3955\n",
      "Epoch: 610, Loss: 515.7904\n",
      "Epoch: 620, Loss: 569.2869\n",
      "Epoch: 630, Loss: 530.5093\n",
      "Epoch: 640, Loss: 539.8671\n",
      "Epoch: 650, Loss: 689.0546\n",
      "Epoch: 660, Loss: 495.0873\n",
      "Epoch: 670, Loss: 478.1584\n",
      "Epoch: 680, Loss: 471.2843\n",
      "Epoch: 690, Loss: 511.9318\n",
      "Epoch: 700, Loss: 460.8949\n",
      "Epoch: 710, Loss: 476.2714\n",
      "Epoch: 720, Loss: 535.6670\n",
      "Epoch: 730, Loss: 452.6179\n",
      "Epoch: 740, Loss: 480.7096\n",
      "Epoch: 750, Loss: 496.9506\n",
      "Epoch: 760, Loss: 452.8202\n",
      "Epoch: 770, Loss: 510.8187\n",
      "Epoch: 780, Loss: 472.6476\n",
      "Epoch: 790, Loss: 444.6380\n",
      "Epoch: 800, Loss: 467.9955\n",
      "Epoch: 810, Loss: 432.6023\n",
      "Epoch: 820, Loss: 536.1107\n",
      "Epoch: 830, Loss: 447.4213\n",
      "Epoch: 840, Loss: 415.1600\n",
      "Epoch: 850, Loss: 501.4990\n",
      "Epoch: 860, Loss: 412.5670\n",
      "Epoch: 870, Loss: 384.3399\n",
      "Epoch: 880, Loss: 446.6091\n",
      "Epoch: 890, Loss: 537.5544\n",
      "Epoch: 900, Loss: 553.1770\n",
      "Epoch: 910, Loss: 510.8153\n",
      "Epoch: 920, Loss: 418.4212\n",
      "Epoch: 930, Loss: 401.0256\n",
      "Epoch: 940, Loss: 370.3328\n",
      "Epoch: 950, Loss: 497.6007\n",
      "Epoch: 960, Loss: 579.2413\n",
      "Epoch: 970, Loss: 420.8783\n",
      "Epoch: 980, Loss: 529.2955\n",
      "Epoch: 990, Loss: 416.9267\n",
      "Epoch: 1000, Loss: 398.7747\n",
      "Epoch: 1010, Loss: 375.6064\n",
      "Epoch: 1020, Loss: 365.6651\n",
      "Epoch: 1030, Loss: 369.0224\n",
      "Epoch: 1040, Loss: 359.9789\n",
      "Epoch: 1050, Loss: 506.9992\n",
      "Epoch: 1060, Loss: 374.9829\n",
      "Epoch: 1070, Loss: 505.5068\n",
      "Epoch: 1080, Loss: 718.9525\n",
      "Epoch: 1090, Loss: 390.1026\n",
      "Epoch: 1100, Loss: 416.0150\n",
      "Epoch: 1110, Loss: 395.5351\n",
      "Epoch: 1120, Loss: 350.0599\n",
      "Epoch: 1130, Loss: 322.9081\n",
      "Epoch: 1140, Loss: 345.4405\n",
      "Epoch: 1150, Loss: 316.1243\n",
      "Epoch: 1160, Loss: 295.1824\n",
      "Epoch: 1170, Loss: 374.0009\n",
      "Epoch: 1180, Loss: 626.2612\n",
      "Epoch: 1190, Loss: 427.2104\n",
      "Epoch: 1200, Loss: 364.8730\n",
      "Epoch: 1210, Loss: 558.0216\n",
      "Epoch: 1220, Loss: 516.5587\n",
      "Epoch: 1230, Loss: 368.0955\n",
      "Epoch: 1240, Loss: 332.0444\n",
      "Epoch: 1250, Loss: 327.9139\n",
      "Epoch: 1260, Loss: 304.0352\n",
      "Epoch: 1270, Loss: 325.0515\n",
      "Epoch: 1280, Loss: 591.5931\n",
      "Epoch: 1290, Loss: 444.9428\n",
      "Epoch: 1300, Loss: 392.8411\n",
      "Epoch: 1310, Loss: 355.7850\n",
      "Epoch: 1320, Loss: 318.4286\n",
      "Epoch: 1330, Loss: 411.4711\n",
      "Epoch: 1340, Loss: 399.3017\n",
      "Epoch: 1350, Loss: 390.4816\n",
      "Epoch: 1360, Loss: 356.7003\n",
      "Epoch: 1370, Loss: 340.6083\n",
      "Epoch: 1380, Loss: 334.2582\n",
      "Epoch: 1390, Loss: 306.3110\n",
      "Epoch: 1400, Loss: 449.7692\n",
      "Epoch: 1410, Loss: 401.5164\n",
      "Epoch: 1420, Loss: 400.1128\n",
      "Epoch: 1430, Loss: 335.6749\n",
      "Epoch: 1440, Loss: 371.5510\n",
      "Epoch: 1450, Loss: 369.8066\n",
      "Epoch: 1460, Loss: 381.4288\n",
      "Epoch: 1470, Loss: 326.0854\n",
      "Epoch: 1480, Loss: 325.1133\n",
      "Epoch: 1490, Loss: 288.2418\n",
      "Epoch: 1500, Loss: 460.0092\n",
      "Epoch: 1510, Loss: 306.8449\n",
      "Epoch: 1520, Loss: 373.8961\n",
      "Epoch: 1530, Loss: 261.2393\n",
      "Epoch: 1540, Loss: 279.7906\n",
      "Epoch: 1550, Loss: 247.2814\n",
      "Epoch: 1560, Loss: 397.3092\n",
      "Epoch: 1570, Loss: 308.5785\n",
      "Epoch: 1580, Loss: 326.6541\n",
      "Epoch: 1590, Loss: 225.3252\n",
      "Epoch: 1600, Loss: 428.3911\n",
      "Epoch: 1610, Loss: 811.8847\n",
      "Epoch: 1620, Loss: 601.0224\n",
      "Epoch: 1630, Loss: 521.9719\n",
      "Epoch: 1640, Loss: 518.1460\n",
      "Epoch: 1650, Loss: 415.5760\n",
      "Epoch: 1660, Loss: 356.0283\n",
      "Epoch: 1670, Loss: 317.3853\n",
      "Epoch: 1680, Loss: 416.1523\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m15000\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39mif\u001b[39;00m (epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n",
      "\u001b[1;32m/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb Cell 11\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m P, _, imbalance_list \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(data, P, imbalance_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ab/apps/nfsolver/notebooks/exploratory/0.4-ab-TrainStableGNN.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Вычисление информационного loss на последнем слое GNN\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/apps/nfsolver/src/models/gnnstableprocessor.py:54\u001b[0m, in \u001b[0;36mGNNStableProcessor.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m     Pl \u001b[39m=\u001b[39m decoder(X)\n\u001b[1;32m     53\u001b[0m     Pl \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(Pl)\n\u001b[0;32m---> 54\u001b[0m     append_results(Pl)\n\u001b[1;32m     56\u001b[0m P \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal(X)\n\u001b[1;32m     57\u001b[0m P \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(P)\n",
      "File \u001b[0;32m~/apps/nfsolver/src/models/gnnstableprocessor.py:43\u001b[0m, in \u001b[0;36mGNNStableProcessor.forward.<locals>.append_results\u001b[0;34m(P_l)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mappend_results\u001b[39m(P_l):\n\u001b[1;32m     40\u001b[0m     _pset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m     41\u001b[0m         data\u001b[39m.\u001b[39mx[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m, data\u001b[39m.\u001b[39mx[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], P_l\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m     )\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     flows, imbalance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbalance_conv(\n\u001b[1;32m     44\u001b[0m         P\u001b[39m=\u001b[39;49m_pset, edge_index\u001b[39m=\u001b[39;49medge_index, edge_attr\u001b[39m=\u001b[39;49medge_attr, node_attr\u001b[39m=\u001b[39;49mnode_attr\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     flows_list\u001b[39m.\u001b[39mappend(flows)\n\u001b[1;32m     47\u001b[0m     imbalance_list\u001b[39m.\u001b[39mappend(imbalance)\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/apps/nfsolver/src/models/balanceconv.py:56\u001b[0m, in \u001b[0;36mBalanceConv.forward\u001b[0;34m(self, P, edge_index, edge_attr, node_attr)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     53\u001b[0m     \u001b[39mself\u001b[39m, P: Tensor, edge_index: Adj, edge_attr: Tensor, node_attr: Tensor\n\u001b[1;32m     54\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     55\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msource_to_target\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 56\u001b[0m     flows_in \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(\n\u001b[1;32m     57\u001b[0m         edge_index\u001b[39m=\u001b[39;49medge_index, p\u001b[39m=\u001b[39;49mP, edge_attr\u001b[39m=\u001b[39;49medge_attr, node_attr\u001b[39m=\u001b[39;49mnode_attr\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtarget_to_source\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     flows_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(\n\u001b[1;32m     62\u001b[0m         edge_index\u001b[39m=\u001b[39medge_index, p\u001b[39m=\u001b[39mP, edge_attr\u001b[39m=\u001b[39medge_attr, node_attr\u001b[39m=\u001b[39mnode_attr\n\u001b[1;32m     63\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:459\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m decomp_args:\n\u001b[1;32m    457\u001b[0m         kwargs[arg] \u001b[39m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 459\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_user_args, edge_index, size,\n\u001b[1;32m    460\u001b[0m                           kwargs)\n\u001b[1;32m    462\u001b[0m msg_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[1;32m    463\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_pre_hooks\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:336\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    335\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_size(size, dim, data)\n\u001b[0;32m--> 336\u001b[0m             data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lift(data, edge_index, dim)\n\u001b[1;32m    338\u001b[0m         out[arg] \u001b[39m=\u001b[39m data\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:272\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     index \u001b[39m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 272\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mindex_select(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim, index)\n\u001b[1;32m    273\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mmin() \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m index\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m src\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim):\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/fx/traceback.py:41\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m [current_meta\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstack_trace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[39m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m traceback\u001b[39m.\u001b[39mformat_list(traceback\u001b[39m.\u001b[39;49mextract_stack()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[1;32m    228\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    376\u001b[0m     result\u001b[39m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39mf_locals))\n\u001b[1;32m    378\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m fnames:\n\u001b[0;32m--> 379\u001b[0m     linecache\u001b[39m.\u001b[39;49mcheckcache(filename)\n\u001b[1;32m    380\u001b[0m \u001b[39m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m~/anaconda3/envs/nfsolver/lib/python3.10/linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mcontinue\u001b[39;00m   \u001b[39m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     stat \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(fullname)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     cache\u001b[39m.\u001b[39mpop(filename, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "losses = []\n",
    "for epoch in range(15000):\n",
    "  loss = train()\n",
    "  losses.append(loss)\n",
    "\n",
    "  if (epoch % 10 == 0):\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Кривая обучения')\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('Функция потерь')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([\n",
    "  [0, 1, 2],\n",
    "  [1, 2, 3]\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Структура данных атрибутов вершин графа:\n",
    "# Расход газа потребителя в узле, млн м3/сут; Давление газа, МПа\n",
    "x = torch.tensor([[0, 7.4], [0.0, 0], [0, 0], [0, 5.4]], dtype=torch.float32)\n",
    "\n",
    "# Структура данных атрибутов дуг графа:\n",
    "# Протяженность, км; Внутренний диаметр трубы, мм\n",
    "edge_attr = torch.tensor([\n",
    "  [38, 1400],\n",
    "  [40, 1400],\n",
    "  [43, 1400]\n",
    "])\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=tensor([[0.1701],\n",
      "        [0.1353],\n",
      "        [0.1353],\n",
      "        [0.1527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1902],\n",
      "         [  -0.2441],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1164],\n",
      "         [   0.2517],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.2435],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1694],\n",
      "         [  -0.2439],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1867],\n",
      "         [   0.2447],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1213],\n",
      "         [   0.2538],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1680],\n",
      "         [   0.2578],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1918],\n",
      "         [   0.2439],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1572],\n",
      "         [  -0.2525],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1513],\n",
      "         [   0.2524],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1902],\n",
      "         [ 243.4343],\n",
      "         [ 166.5817],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1164],\n",
      "         [ 242.8647],\n",
      "         [ 166.9824],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 242.9484],\n",
      "         [ 167.0715],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1694],\n",
      "         [ 243.4134],\n",
      "         [ 166.5551],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1867],\n",
      "         [ 242.9420],\n",
      "         [ 167.0660],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1213],\n",
      "         [ 242.8675],\n",
      "         [ 166.9908],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[-243.1680],\n",
      "         [ 242.9102],\n",
      "         [ 167.0549],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[-243.1918],\n",
      "         [ 242.9479],\n",
      "         [ 167.0717],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[-243.1572],\n",
      "         [ 243.4098],\n",
      "         [ 166.5308],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[-243.1513],\n",
      "         [ 242.8989],\n",
      "         [ 167.0281],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "P=tensor([[0.1701],\n",
      "        [0.1353],\n",
      "        [0.1353],\n",
      "        [0.1527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1902],\n",
      "         [  -0.2441],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1164],\n",
      "         [   0.2517],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.2435],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1694],\n",
      "         [  -0.2439],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1867],\n",
      "         [   0.2447],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1213],\n",
      "         [   0.2538],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1680],\n",
      "         [   0.2578],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1918],\n",
      "         [   0.2439],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1572],\n",
      "         [  -0.2525],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1513],\n",
      "         [   0.2524],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1902],\n",
      "         [ 243.4343],\n",
      "         [ 166.5817],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1164],\n",
      "         [ 242.8647],\n",
      "         [ 166.9824],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 242.9484],\n",
      "         [ 167.0715],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1694],\n",
      "         [ 243.4134],\n",
      "         [ 166.5551],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1867],\n",
      "         [ 242.9420],\n",
      "         [ 167.0660],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1213],\n",
      "         [ 242.8675],\n",
      "         [ 166.9908],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[-243.1680],\n",
      "         [ 242.9102],\n",
      "         [ 167.0549],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[-243.1918],\n",
      "         [ 242.9479],\n",
      "         [ 167.0717],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[-243.1572],\n",
      "         [ 243.4098],\n",
      "         [ 166.5308],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[-243.1513],\n",
      "         [ 242.8989],\n",
      "         [ 167.0281],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "P=tensor([[0.1701],\n",
      "        [0.1353],\n",
      "        [0.1353],\n",
      "        [0.1527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1902],\n",
      "         [  -0.2441],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1164],\n",
      "         [   0.2517],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.2435],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1694],\n",
      "         [  -0.2439],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1867],\n",
      "         [   0.2447],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1213],\n",
      "         [   0.2538],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1680],\n",
      "         [   0.2578],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1918],\n",
      "         [   0.2439],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1572],\n",
      "         [  -0.2525],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1513],\n",
      "         [   0.2524],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1902],\n",
      "         [ 243.4343],\n",
      "         [ 166.5817],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1164],\n",
      "         [ 242.8647],\n",
      "         [ 166.9824],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 242.9484],\n",
      "         [ 167.0715],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1694],\n",
      "         [ 243.4134],\n",
      "         [ 166.5551],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1867],\n",
      "         [ 242.9420],\n",
      "         [ 167.0660],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1213],\n",
      "         [ 242.8675],\n",
      "         [ 166.9908],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[-243.1680],\n",
      "         [ 242.9102],\n",
      "         [ 167.0549],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[-243.1918],\n",
      "         [ 242.9479],\n",
      "         [ 167.0717],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[-243.1572],\n",
      "         [ 243.4098],\n",
      "         [ 166.5308],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[-243.1513],\n",
      "         [ 242.8989],\n",
      "         [ 167.0281],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "P=tensor([[0.1701],\n",
      "        [0.1353],\n",
      "        [0.1353],\n",
      "        [0.1527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1902],\n",
      "         [  -0.2441],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1164],\n",
      "         [   0.2517],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.2435],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1694],\n",
      "         [  -0.2439],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1867],\n",
      "         [   0.2447],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1213],\n",
      "         [   0.2538],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1680],\n",
      "         [   0.2578],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1918],\n",
      "         [   0.2439],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1572],\n",
      "         [  -0.2525],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1513],\n",
      "         [   0.2524],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1902],\n",
      "         [ 243.4343],\n",
      "         [ 166.5817],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1164],\n",
      "         [ 242.8647],\n",
      "         [ 166.9824],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 242.9484],\n",
      "         [ 167.0715],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1694],\n",
      "         [ 243.4134],\n",
      "         [ 166.5551],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1867],\n",
      "         [ 242.9420],\n",
      "         [ 167.0660],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1213],\n",
      "         [ 242.8675],\n",
      "         [ 166.9908],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[-243.1680],\n",
      "         [ 242.9102],\n",
      "         [ 167.0549],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[-243.1918],\n",
      "         [ 242.9479],\n",
      "         [ 167.0717],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[-243.1572],\n",
      "         [ 243.4098],\n",
      "         [ 166.5308],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[-243.1513],\n",
      "         [ 242.8989],\n",
      "         [ 167.0281],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "P=tensor([[0.1701],\n",
      "        [0.1353],\n",
      "        [0.1353],\n",
      "        [0.1527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1902],\n",
      "         [  -0.2441],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1164],\n",
      "         [   0.2517],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.2435],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1694],\n",
      "         [  -0.2439],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1867],\n",
      "         [   0.2447],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1213],\n",
      "         [   0.2538],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1680],\n",
      "         [   0.2578],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1918],\n",
      "         [   0.2439],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1572],\n",
      "         [  -0.2525],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1513],\n",
      "         [   0.2524],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1902],\n",
      "         [ 243.4343],\n",
      "         [ 166.5817],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1164],\n",
      "         [ 242.8647],\n",
      "         [ 166.9824],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 242.9484],\n",
      "         [ 167.0715],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1694],\n",
      "         [ 243.4134],\n",
      "         [ 166.5551],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1867],\n",
      "         [ 242.9420],\n",
      "         [ 167.0660],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1213],\n",
      "         [ 242.8675],\n",
      "         [ 166.9908],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[-243.1680],\n",
      "         [ 242.9102],\n",
      "         [ 167.0549],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[-243.1918],\n",
      "         [ 242.9479],\n",
      "         [ 167.0717],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[-243.1572],\n",
      "         [ 243.4098],\n",
      "         [ 166.5308],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[-243.1513],\n",
      "         [ 242.8989],\n",
      "         [ 167.0281],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "P=tensor([[0.1701],\n",
      "        [0.1353],\n",
      "        [0.1353],\n",
      "        [0.1527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1902],\n",
      "         [  -0.2441],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1164],\n",
      "         [   0.2517],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.2435],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1694],\n",
      "         [  -0.2439],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1867],\n",
      "         [   0.2447],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1213],\n",
      "         [   0.2538],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1680],\n",
      "         [   0.2578],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1918],\n",
      "         [   0.2439],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1572],\n",
      "         [  -0.2525],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1513],\n",
      "         [   0.2524],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1902],\n",
      "         [ 243.4343],\n",
      "         [ 166.5817],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1164],\n",
      "         [ 242.8647],\n",
      "         [ 166.9824],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 242.9484],\n",
      "         [ 167.0715],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1694],\n",
      "         [ 243.4134],\n",
      "         [ 166.5551],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1867],\n",
      "         [ 242.9420],\n",
      "         [ 167.0660],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1213],\n",
      "         [ 242.8675],\n",
      "         [ 166.9908],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[-243.1680],\n",
      "         [ 242.9102],\n",
      "         [ 167.0549],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[-243.1918],\n",
      "         [ 242.9479],\n",
      "         [ 167.0717],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[-243.1572],\n",
      "         [ 243.4098],\n",
      "         [ 166.5308],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[-243.1513],\n",
      "         [ 242.8989],\n",
      "         [ 167.0281],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "P=tensor([[0.1701],\n",
      "        [0.1353],\n",
      "        [0.1353],\n",
      "        [0.1527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1902],\n",
      "         [  -0.2441],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1164],\n",
      "         [   0.2517],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.2435],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1694],\n",
      "         [  -0.2439],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1867],\n",
      "         [   0.2447],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1213],\n",
      "         [   0.2538],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1680],\n",
      "         [   0.2578],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1918],\n",
      "         [   0.2439],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1572],\n",
      "         [  -0.2525],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1513],\n",
      "         [   0.2524],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1902],\n",
      "         [ 243.4343],\n",
      "         [ 166.5817],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1164],\n",
      "         [ 242.8647],\n",
      "         [ 166.9824],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 242.9484],\n",
      "         [ 167.0715],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1694],\n",
      "         [ 243.4134],\n",
      "         [ 166.5551],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1867],\n",
      "         [ 242.9420],\n",
      "         [ 167.0660],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1213],\n",
      "         [ 242.8675],\n",
      "         [ 166.9908],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[-243.1680],\n",
      "         [ 242.9102],\n",
      "         [ 167.0549],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[-243.1918],\n",
      "         [ 242.9479],\n",
      "         [ 167.0717],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[-243.1572],\n",
      "         [ 243.4098],\n",
      "         [ 166.5308],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[-243.1513],\n",
      "         [ 242.8989],\n",
      "         [ 167.0281],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "P=tensor([[0.1701],\n",
      "        [0.1353],\n",
      "        [0.1353],\n",
      "        [0.1527]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "flows=tensor([[[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1902],\n",
      "         [  -0.2441],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1164],\n",
      "         [   0.2517],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.2435],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1694],\n",
      "         [  -0.2439],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1867],\n",
      "         [   0.2447],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1919],\n",
      "         [   0.0000],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1213],\n",
      "         [   0.2538],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1680],\n",
      "         [   0.2578],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1918],\n",
      "         [   0.2439],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1572],\n",
      "         [  -0.2525],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[   0.0000],\n",
      "         [ 243.1513],\n",
      "         [   0.2524],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "imbalance=tensor([[[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1902],\n",
      "         [ 243.4343],\n",
      "         [ 166.5817],\n",
      "         [-166.8258]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1164],\n",
      "         [ 242.8647],\n",
      "         [ 166.9824],\n",
      "         [-166.7307]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 242.9484],\n",
      "         [ 167.0715],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1694],\n",
      "         [ 243.4134],\n",
      "         [ 166.5551],\n",
      "         [-166.7991]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1867],\n",
      "         [ 242.9420],\n",
      "         [ 167.0660],\n",
      "         [-166.8213]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1919],\n",
      "         [ 243.1919],\n",
      "         [ 166.8280],\n",
      "         [-166.8280]],\n",
      "\n",
      "        [[-243.1213],\n",
      "         [ 242.8675],\n",
      "         [ 166.9908],\n",
      "         [-166.7370]],\n",
      "\n",
      "        [[-243.1680],\n",
      "         [ 242.9102],\n",
      "         [ 167.0549],\n",
      "         [-166.7972]],\n",
      "\n",
      "        [[-243.1918],\n",
      "         [ 242.9479],\n",
      "         [ 167.0717],\n",
      "         [-166.8278]],\n",
      "\n",
      "        [[-243.1572],\n",
      "         [ 243.4098],\n",
      "         [ 166.5308],\n",
      "         [-166.7833]],\n",
      "\n",
      "        [[-243.1513],\n",
      "         [ 242.8989],\n",
      "         [ 167.0281],\n",
      "         [-166.7757]]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "565 ms ± 24 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# %%timeit \n",
    "# Attention: При выводе значений давления краевые значения не выводятся, но учитываются в расчете\n",
    "P, flows, imbalance = model(data)\n",
    "print(f'{P=}')\n",
    "print(f'{flows=}')\n",
    "print(f'{imbalance=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/compile.py:28: UserWarning: Could not convert the 'model' into a jittable version. As such, 'torch.compile' may currently fail to correctly optimize your model. 'MessagePassing.jittable()' reported the following error: TorchScript support requires the definition of the types passed to `propagate()`. Please specify them via\n",
      "\n",
      "propagate_type = {\"arg1\": type1, \"arg2\": type2, ... }\n",
      "\n",
      "or via\n",
      "\n",
      "# propagate_type: (arg1: type1, arg2: type2, ...)\n",
      "\n",
      "inside the `MessagePassing` module.\n",
      "  warnings.warn(JIT_WARNING.format(error=e))\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "compiled = torch_geometric.compile(model)\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-23 12:11:04,140] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT _collect /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py line 317 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1118, in create_backend\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Found NVIDIA GeForce GTX 1070 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised RuntimeError: Found NVIDIA GeForce GTX 1070 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "[2023-09-23 12:11:04,170] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT _lift /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py line 249 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_inductor/scheduler.py\", line 1118, in create_backend\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Found NVIDIA GeForce GTX 1070 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised RuntimeError: Found NVIDIA GeForce GTX 1070 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/apps/nfsolver/src/models/gnnsvonv.py\", line 108, in message\n",
      "    out_message = mlp(tmp)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:04,343] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT message /home/ab/apps/nfsolver/src/models/gnnsvonv.py line 99 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:04,478] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT forward /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/container.py line 215 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in AddBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/norm/layer_norm.py\", line 96, in forward\n",
      "    out = out * self.weight + self.bias\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:04,557] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT forward /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/norm/layer_norm.py line 65 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in DivBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/utils/scatter.py\", line 84, in scatter\n",
      "    return out / broadcast(count, out, dim)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py\", line 155, in reduce\n",
      "    return scatter(x, index, dim, dim_size, reduce)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py\", line 34, in forward\n",
      "    return self.reduce(x, index, ptr, dim_size, dim, reduce='mean')\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py\", line 608, in aggregate\n",
      "    return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:04,661] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT aggregate /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py line 595 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in DivBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/utils/scatter.py\", line 84, in scatter\n",
      "    return out / broadcast(count, out, dim)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py\", line 155, in reduce\n",
      "    return scatter(x, index, dim, dim_size, reduce)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py\", line 34, in forward\n",
      "    return self.reduce(x, index, ptr, dim_size, dim, reduce='mean')\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py\", line 109, in __call__\n",
      "    return super().__call__(x, index, ptr, dim_size, dim, **kwargs)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:04,767] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT __call__ /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py line 86 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in DivBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/utils/scatter.py\", line 84, in scatter\n",
      "    return out / broadcast(count, out, dim)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py\", line 155, in reduce\n",
      "    return scatter(x, index, dim, dim_size, reduce)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py\", line 34, in forward\n",
      "    return self.reduce(x, index, ptr, dim_size, dim, reduce='mean')\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:04,862] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT forward /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py line 31 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in DivBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/utils/scatter.py\", line 84, in scatter\n",
      "    return out / broadcast(count, out, dim)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py\", line 155, in reduce\n",
      "    return scatter(x, index, dim, dim_size, reduce)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:04,952] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT reduce /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py line 146 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in DivBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/utils/scatter.py\", line 84, in scatter\n",
      "    return out / broadcast(count, out, dim)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:05,045] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT scatter /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/utils/scatter.py line 23 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in AddBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/apps/nfsolver/src/models/gnnsvonv.py\", line 96, in <graph break in forward>\n",
      "    X = X + self.alpha * psi\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:05,397] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT <graph break in forward> /home/ab/apps/nfsolver/src/models/gnnsvonv.py line 91 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in MulBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/apps/nfsolver/src/models/balanceconv.py\", line 39, in _calculate_flows\n",
      "    3.32\n",
      " |   File \"/home/ab/apps/nfsolver/src/models/balanceconv.py\", line 86, in message\n",
      "    flows = self._calculate_flows(\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:05,694] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT message /home/ab/apps/nfsolver/src/models/balanceconv.py line 68 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in MulBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/apps/nfsolver/src/models/balanceconv.py\", line 39, in _calculate_flows\n",
      "    3.32\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:05,831] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT _calculate_flows /home/ab/apps/nfsolver/src/models/balanceconv.py line 20 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in ScatterAddBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/utils/scatter.py\", line 74, in scatter\n",
      "    return src.new_zeros(size).scatter_add_(dim, index, src)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py\", line 155, in reduce\n",
      "    return scatter(x, index, dim, dim_size, reduce)\n",
      " |   File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py\", line 21, in forward\n",
      "    return self.reduce(x, index, ptr, dim_size, dim, reduce='sum')\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:05,894] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT forward /home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py line 18 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n",
      "/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in SubBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/ab/apps/nfsolver/src/models/balanceconv.py\", line 65, in <graph break in forward>\n",
      "    nodes_imbalance = torch.subtract(flows_in, flows_out)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "[2023-09-23 12:11:06,067] torch._dynamo.convert_frame: [ERROR] WON'T CONVERT <graph break in forward> /home/ab/apps/nfsolver/src/models/balanceconv.py line 61 \n",
      "due to: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py\", line 410, in local_scalar_dense\n",
      "    raise DataDependentOutputException(func)\n",
      "torch._subclasses.fake_tensor.DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ab/anaconda3/envs/nfsolver/lib/python3.10/site-packages/torch/_dynamo/output_graph.py\", line 675, in call_user_compiler\n",
      "    raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "torch._dynamo.exc.BackendCompilerFailed: debug_wrapper raised DataDependentOutputException: aten._local_scalar_dense.default\n",
      "\n",
      "Set torch._dynamo.config.verbose=True for more information\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 ms ± 18.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "P, flows, imbalance = compiled(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfsolver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
